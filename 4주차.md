# clustering
클러스터 내의 기준과 데이터들의 거리합 최소
조건>
![image](https://user-images.githubusercontent.com/69943167/125376449-fac1cf00-e3c5-11eb-8c2f-6253f4f4ddc5.png)
![image](https://user-images.githubusercontent.com/69943167/125376465-031a0a00-e3c6-11eb-8921-390d197594e6.png)

이 두개의 조건을 만족시키는 중앙점을 계산해야함.
클러스터 간의 거리가 멀면 오판할 가능성이 줄어든다.

![image](https://user-images.githubusercontent.com/69943167/125376557-39578980-e3c6-11eb-8969-03a2cc41727d.png)

predict 함수를 이용하면 점 위치 확인 가능(1과 0 사이에서 갑자기 바뀌는 위치)

각 기준점으로부터 euclidian 거리 계산.

```
from sklearn.datasets import load_iris
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math 
%matplotlib inline

# 데이터 만들기
iris = load_iris()
iris_data = iris.data
iris_data_pd = pd.DataFrame(iris_data, columns=iris.feature_names)
print(iris_data_pd)

# 점으로 찍어보기
petals = pd.DataFrame(iris_data_pd.values[:, 2:4], columns = ['petal length (cm)', 'petal width (cm)'])
plt.scatter(petals.values[:, 0], petals.values[:,1])
plt.show()

# 색으로 나타내기
from sklearn.cluster import KMeans

plt.figure(figsize=(7,5))
km = KMeans(n_clusters=2, random_state=20)
km.fit(iris_data_pd.iloc[:, 2:4])
y_pred = km.predict(iris_data_pd.iloc[:, 2:4])
plt.scatter(iris_data_pd.iloc[:,2], iris_data_pd.iloc[:,3], c=y_pred)
plt.title("Clustering")
plt.xlabel('petal length')
plt.ylabel('petal width')

plt.show()

# 점의 위치 먼저 확인(다른 점 하나)
print (km.predict(iris_data_pd.iloc[:, 2:4]))

# 다른 점 하나 위치
print(iris_data_pd.iloc[98, 2:4])

# 기준점으로부터 euclidian 거리 계산
def distance(x1, y1, x2, y2):
  dx = x2 -  x1
  dy = y2 - y1
  squared = dx**2 + dy**2
  result = math.sqrt(squared)
  return result

print('0 cluster distance: ', distance(iris_data_pd.iloc[98, 2], iris_data_pd.iloc[98, 3], km.cluster_centers_[0][0], km.cluster_centers_[0][1]))
print('1 cluster distance: ', distance(iris_data_pd.iloc[98, 2], iris_data_pd.iloc[98, 3], km.cluster_centers_[1][0], km.cluster_centers_[1][1]))

# 클러스터의 분류 갯수를 바꿔보면서 확인
n_cluster = [3,4,6,12]

for i in n_cluster:
  count = 1
  km = KMeans(n_clusters= i, random_state=20)
  km.fit(iris_data_pd.iloc[:, 2:4])
  y_pred = km.predict(iris_data_pd.iloc[:, 2:4])
  plt.figure(count)
  plt.scatter(iris_data_pd.iloc[:,2], iris_data_pd.iloc[:, 3], c=y_pred)
  plt.title("Clustering = "+str(i))
  plt.xlabel('petal length')
  plt.ylabel('petal width')
  count=count+1
  plt.show()

# Voronoi 그래프로 묘사
km12 = KMeans(n_clusters = 8, random_state = 20)
km12.fit(iris_data_pd.iloc[:, 2:4])
y_pred12 = km12.predict(iris_data_pd.iloc[:, 2:4])
plt.title("Clustering")
plt.xlabel("petal length")
plt.ylabel('petal width')
graph1 = plt.scatter(iris_data_pd.iloc[:, 2], iris_data_pd.iloc[:, 3], c=y_pred12)
plt.show()

h = .02
km12 = KMeans(n_clusters = 8, random_state=20)
km12.fit(iris_data_pd.iloc[:, 2:4])
y_pred12 = km12.predict(iris_data_pd.iloc[:, 2:4])

# 경계선에 컬러주기
x_min, x_max = iris_data_pd.iloc[:, 2].min() - 1, iris_data_pd.iloc[:, 2].max() + 1 
y_min, y_max = iris_data_pd.iloc[:, 3].min() - 1, iris_data_pd.iloc[:, 3].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))       

# 라벨 포인트 모으기
Z = km12.predict(np.c_[xx.ravel(), yy.ravel()])

# Put the result into a color plot 
Z = Z.reshape(xx.shape) 
plt.figure(1) 
plt.clf() 
plt.imshow(Z, interpolation='nearest', extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect='auto', 
origin='lower') 
plt.plot(iris_data_pd.iloc[:, 2], iris_data_pd.iloc[:, 3], 'bo', markersize=2) 

# Plot the centroids as a white X 
centroids = km12.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1], marker='^', s=16, linewidths=3, color='r', zorder=10)
plt.xlim(x_min, x_max) 
plt.ylim(y_min, y_max)
plt.xticks(()) 
plt.yticks(())
plt.show()
```
